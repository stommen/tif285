{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "- See deadline on the course web page\n",
    "- This problem set is solved individually. See examination rules on the course web page and the explanation of the examination procedure below.\n",
    "- The two notebooks for each problem set contain a number of basic and extra problems; you can choose which and how many to work on. The extra problems are usually more challenging.\n",
    "- Students are allowed to discuss together and help each other when solving the problems. However, every student must understand their submitted solution in the sense that they should be able to explain and discuss them with a peer or with a teacher.\n",
    "- While discussions with your peers are allowed (and even encouraged), direct plagiarism is not. Every student must reach their own understanding of submitted solutions according to the definition in the previous point.\n",
    "- The use of coding assistance from code generating artificial intelligence tools is allowed. However, every student must reach their own understanding of submitted solutions (including employed algorithms) according to the definition above.\n",
    "- Some problems include checkpoints in the form of `assert` statements. These usually check some basic functionality and you should make sure that your code passes these statements without raising an `AssertionError`. \n",
    "- Do not use other python modules than the ones included in the `environment.yml` file in the course github repo. \n",
    "\n",
    "- **Important:** The grading of problem sets requires **all** of the following actions:\n",
    "  1. Make sure to always complete **Task 0** in the header part of the notebook and that this part does not raise any `AssertionError`(s).\n",
    "  1. **Complete** the corresponding questions in Yata for every task that you have completed. This usually involves copying and pasting some code from your solution notebook and passing the code tests. You need to have a green check mark on Yata to get the corresponding points.\n",
    "  1. **Upload** your solution in the form of your edited version of this Jupyter notebook via the appropriate assignment module in Canvas (separate for basic and extra tasks). It is the code and results in your submitted notebook that is considered to be your hand-in solution.\n",
    "  1. If selected, be **available for a discussion** of your solution with one of the teachers on the Monday afternoon exercise session directly following the problem set deadline. No extra preparation is needed for these discussions apart from familiarity with your own solution. A list of randomly selected students will be published on the course web page around Monday noon. During the afternoon session that same day, students will be called in the numbered order until the end of the list (or the end of the exercise session). You must inform the responsible teacher as soon as possible following the publication of the student list if you can not be physically present at the exercise session (in which case we will have the discussion on zoom). An oral examination (on all aspects of the course) will be arranged during the exam week for students that do not show up for their discussion slot, or that fail to demonstrate familiarity with their hand-in solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "- Make sure that the **run time is smaller than a few minutes**. If needed you might have to reduce some computational tasks; e.g. by decreasing the number of grid points or sampling steps. Please ask the supervisors if you are uncertain about the run time. \n",
    "\n",
    "- Your solutions are usually expected where it says `YOUR CODE HERE` or <font color=\"red\">\"PLEASE WRITE YOUR ANSWER HERE\"</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 0 \n",
    "#### (0 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "251105c400969a6d24e9f7ec4883888e",
     "grade": false,
     "grade_id": "cell-6f99a2583f9fb27d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "By changing the below boolean variable `student_self_assessment` to `True` you attest that:\n",
    "- All handed in solutions were produced by yourself in the sense that you understand your solutions and should be able to explain and discuss them with a peer or with a teacher.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "64a7020fd0e62e5b51ef4470ae1c797f",
     "grade": false,
     "grade_id": "student-self-assessment",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "student_self_assessment = False\n",
    "\n",
    "# \n",
    "# YOUR CODE HERE\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d873afed15d2d3de2ef460d53fccf90f",
     "grade": true,
     "grade_id": "cell-795bedd2908899aa",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert student_self_assessment == True, 'You must assert the individual solution statements.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 1 (Basic problems)\n",
    "\n",
    "**Learning from data [TIF285], Chalmers, Fall 2024**\n",
    "\n",
    "Last revised: 14-Aug-2024 by Christian Forssen [christian.forssen@chalmers.se]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installations\n",
    "Perform the installations and preparations that are described in the Getting Started instructions. At the end you should have:\n",
    "\n",
    "1. downloaded the current version of the course material from the github repository or from the course web page;\n",
    "2. a running python installation that includes the modules listed in the environment.yml file (e.g. numpy, matplotlib, pandas, emcee, scikit-learn, ...);\n",
    "3. been able to open and run the Jupyter Notebooks with the first week exercises.\n",
    "Ask the computer lab supervisors for assistance if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cffc7d4975be42d36ea3279085c8bcee",
     "grade": false,
     "grade_id": "import",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Modules needed for tests and file system operations\n",
    "import sys\n",
    "\n",
    "import os\n",
    "\n",
    "# Where to save the figures and data files\n",
    "DATA_ID = \"DataFiles/\"\n",
    "if not os.path.exists(DATA_ID):\n",
    "    os.makedirs(DATA_ID)\n",
    "\n",
    "# Make sure that you are running python with version >= 3.x\n",
    "#\n",
    "# Import the following python modules with\n",
    "# the specified abreviations:\n",
    "# ---\n",
    "# numpy as np\n",
    "# scipy as scipy\n",
    "# scipy.stats as stats\n",
    "# pandas as pd\n",
    "# matplotlib.pyplot as plt\n",
    "# sklearn as skl\n",
    "# emcee as emcee\n",
    "\n",
    "\n",
    "# \n",
    "# YOUR CODE HERE\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c6a82073d8b8c74026808c8bacccad6d",
     "grade": true,
     "grade_id": "correct_import",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide_code"
    ]
   },
   "outputs": [],
   "source": [
    "# TESTS TO CHECK YOUR CODE\n",
    "# ---\n",
    "assert sys.version_info.major>=3, \\\n",
    "    'You are running Python version'+\\\n",
    "    f'{sys.version_info.major}.{sys.version_info.minor}'\n",
    "\n",
    "modules = [('numpy','np'), ('scipy', 'scipy'), \\\n",
    "           ('pandas', 'pd'), ('matplotlib.pyplot', 'plt'), \\\n",
    "           ('sklearn', 'skl'), ('emcee', 'emcee')]\n",
    "for (_module, _module_abbrev) in modules:\n",
    "    assert _module in sys.modules and _module_abbrev in dir(),\\\n",
    "        f'Module {_module} not loaded properly.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random samples\n",
    "In this course there are $N$ students and three problem sets.\n",
    "The random selection of students for problem set discussions is performed by drawing $N$ samples of three random variables $(X_1, X_2, X_3)$. These are arranged in an array of shape (N,3) as follows \n",
    "$$\n",
    "\\left(\n",
    "\\begin{array}{ccc}\n",
    "x_1(1) & x_2(1) & x_3(1) \\\\\n",
    "x_1(2) & x_2(2) & x_3(2) \\\\\n",
    "\\vdots & \\vdots & \\vdots \\\\\n",
    "x_1(N) & x_2(N) & x_3(N)\n",
    "\\end{array}\n",
    "\\right).\n",
    "$$\n",
    "The students with the lowest values of the respective random variable will then be invited for discussions with a teaching assistant. E.g., for problem set 1 there will be an ordered list of students $(k, l, m, \\ldots)$, where $x_1(k) < x_1(l) < x_1(m) < \\ldots$.\n",
    "\n",
    "It is considered fair that all students have the same probability to draw at least one small number, but it should be less likely to draw two small numbers. This can be achieved by making the random variables dependent, more specifically by making the covariance negative (anticorrelated). Here we use a correlated, multivariate Gaussian\n",
    "$$\n",
    "(X_1, X_2, X_3) \\sim \\mathcal{N}\\left( \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma} \\right),\n",
    "$$\n",
    "with mean and covariance\n",
    "$$\n",
    "\\boldsymbol{\\mu} = (0,0,0),\\quad\n",
    "\\boldsymbol{\\Sigma} = \\left(\n",
    "\\begin{array}{ccc}\n",
    "1 & -0.49 & -0.49 \\\\\n",
    "-0.49 & 1 & -0.49 \\\\\n",
    "-0.49 & -0.49 & 1\n",
    "\\end{array}\n",
    "\\right),\n",
    "$$ \n",
    "which means that every univariate, marginal distribution will be a standard normal ($\\mu=0, \\sigma^2=1$).\n",
    "\n",
    "Take a minute to consider the reason for making the random variables anticorrelated (it is instructive to visualize the multivariate distribution) and the fact that the correlation factor cannot be more negative than -0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task (see also Yata):** Consider a class with 6 students. Use the method `multivariate_normal` from `scipy.stats` and generate an array of shape (6,3) with samples from the distribution defined in Problem 1. Print the result. \n",
    "\n",
    "*Important*: Use the `numpy.random.default_rng` method with the seed=2024 to initiate a random number generator instance. This instance should then be used as a `random_state` when generating the samples. See the example in the Statistics chapter of the lecture notes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0c013c5f1717d83336961f1ad005a36c",
     "grade": false,
     "grade_id": "P1array",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \n",
    "# YOUR CODE HERE\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task (see also Yata):** Create a `Pandas.DataFrame` with the sample array from the previous task. The columns should be labeled ['X1', 'X2', 'X3'] while the row indices should be ['Student 1', 'Student 2', 'Student 3', ...]. Print the DataFrame (in the notebook you can try the more fancy option `display`, while you should use `print` on Yata).\n",
    "\n",
    "Assume that only the first two students from each ordered list are selected. Which student(s) will not be selected for any of the problem sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b566ad5dce8ad7a797ac9f7dc9130a2",
     "grade": false,
     "grade_id": "P1df",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# \n",
    "# YOUR CODE HERE\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Non-linear minimization**\n",
    "\n",
    "In this problem you should find the parameter $\\theta$ that minimizes the function\n",
    "$$\n",
    "f(\\theta) = \\sin(6 \\theta) + 0.2 \\theta^2 - 0.7 \\theta\n",
    "$$\n",
    "on the interval $\\theta \\in [-5,5]$.\n",
    "\n",
    "The aim is to find the position of the minimum $\\theta^*$ to within $\\pm 0.05$ under the constraint that we would like to make as few function evaluations as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Grid search\n",
    "\n",
    "**Task (see also Yata)**\n",
    "Plot the true function and indicate the position of the minimum\n",
    "What is the position of the *global* minimum (with at least three significant digits)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4712ffaeda8af786518cc69cc8ce0655",
     "grade": false,
     "grade_id": "P2gridsearch",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "theta_min =  -5.\n",
    "theta_max =  5.\n",
    "\n",
    "# \n",
    "# YOUR CODE HERE\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Find the minimum using `scipy.optimize.minimize` with `method='Nelder-Mead'`. \n",
    "* Choose the starting point randomly from a uniform pdf $U(-5,5)$. \n",
    "* Repeat one hundred times. **Do you always get the same minimum?**\n",
    "* More specifically, set the tolerance of the optimizer to `tol=0.01` and check for success by the criterion $|\\theta^* - \\theta^*_\\mathrm{opt}| < 0.05$, where $\\theta^*_\\mathrm{opt}$ is the result from the optimizer.\n",
    "* Be quantitative about the average number of function evaluations that are needed per successful optimization. Compute the ratio of the total number of function evaluations number (summed over the 100 tries with different starting points) with the number of successful attempts.  \n",
    "  *Hint*: The number of function evaluations from a `scipy.optimize.minimize` result is returned in the ``OptimizeResult`` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc19582220e787463c42518b5178adf7",
     "grade": false,
     "grade_id": "P2scipy",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \n",
    "# YOUR CODE HERE\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Implement a gradient descent method to perform this minimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "781329326e87ea66d8361cf4c447eb89",
     "grade": false,
     "grade_id": "P2gd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \n",
    "# YOUR CODE HERE\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "481b69449dbb031239ec7db3f6dde3fc",
     "grade": false,
     "grade_id": "P3generate",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Generate noisy data with a quadratic feature\n",
    "# use the following code:\n",
    "seed = 42\n",
    "rng = np.random.default_rng(seed)\n",
    "\n",
    "m = 100 # Number of data\n",
    "\n",
    "# X are picked uniform random [0,2]\n",
    "X = rng.uniform(low=0.0, high=2.0, size=(m, 1))\n",
    "# Linear relation to the predicted value, but with Gaussian noise (mean=0, standard deviation=0.2)\n",
    "theta_true = [0.25, 1, 0.75]\n",
    "noise_std = 0.2\n",
    "y = theta_true[2] * X**2 + theta_true[1] * X + theta_true[0] +  rng.normal(loc=0.0, scale=noise_std, size=(m,1))\n",
    "\n",
    "# Below is a hidden code block that is used in the solution notebook to save the data. \n",
    "# \n",
    "# Please ignore the comment in this cell that says \"YOUR CODE HERE\". It gets added automatically.\n",
    "# No solution code is needed here.\n",
    "#\n",
    "# \n",
    "# YOUR CODE HERE\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Linear regression using the Normal Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task (see also Yata):** Create a python function `design_matrix` that returns the design matrix for a polynomial model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f281da58c59dffe144d18c64b30cf347",
     "grade": false,
     "grade_id": "design_matrix",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def design_matrix(X, degree=2):\n",
    "    \"\"\"\n",
    "    Returns a design matrix.\n",
    "    \n",
    "    Args:\n",
    "        X: Array of shape (m,1) with 'm' independent data.\n",
    "        degree: Integer with the degree of the polynomial. \n",
    "                  Note that a degree-n polynomial has n+1 coefficients.\n",
    "                  \n",
    "    Returns:\n",
    "        X_d: Design matrix of shape (m, order+1).\n",
    "    \"\"\"\n",
    "    # \n",
    "    # YOUR CODE HERE\n",
    "    # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df0b83f3837a71a88749810d0a538cdf",
     "grade": true,
     "grade_id": "correct_design_matrix",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TESTS TO CHECK YOUR CODE\n",
    "# ---\n",
    "assert design_matrix(X).shape == (len(X),3)\n",
    "assert design_matrix(X)[:,0].all() == 1\n",
    "assert design_matrix(X)[0,1] == X[0]\n",
    "assert design_matrix(X)[0,2] == X[0]**2\n",
    "\n",
    "ratio = design_matrix(X)[:,2]/design_matrix(X)[:,1]**2\n",
    "assert ratio.all() == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task (see also Yata):** Complete the python method `solve_normal_equation` that solves the normal equation using matrix inversion. This function can be used to fit a quadratic model to the data generated for this problem.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "350da970376594885f058c64685baf17",
     "grade": false,
     "grade_id": "solve_normal_equation",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def solve_normal_equation(X_d, y):\n",
    "    \"\"\"\n",
    "    Solve the normal equation.\n",
    "    \n",
    "    Args:\n",
    "        X_d: Design matrix of shape (m,n) with 'm' independent data\n",
    "               and 'n' features.\n",
    "        y: Dependent data of shape (m,1).\n",
    "                  \n",
    "    Returns:\n",
    "        theta_best: Best parameters, array of shape (n,).\n",
    "    \"\"\"\n",
    "    # \n",
    "    # YOUR CODE HERE\n",
    "    # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4924d5fea0dca84cebf69057fc6d8b9d",
     "grade": true,
     "grade_id": "correct_solve_normal_equation",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TESTS TO CHECK YOUR CODE\n",
    "# ---\n",
    "assert (solve_normal_equation(design_matrix(X), y)).shape==(3,),\\\n",
    "    'Return object has wrong shape. Maybe the `flatten` method will be useful?'\n",
    "theta_star = np.array([0.20661169, 1.10887503, 0.69743377])\n",
    "theta_residuals = solve_normal_equation(design_matrix(X), y) - theta_star\n",
    "assert (abs(theta_residuals)<1e-7).all(), f'The solution to the normal equation is of low precision. theta_residulas = {abs(theta_residuals)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Gradient descent\n",
    "Gradient descent optimization is not really needed for linear regression since we can solve the normal equation exactly. However, it is instructive to implement it yourself and to be able to compare with a known solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task (see also Yata)** \n",
    "Define a function to compute the gradient for the linear regression cost function (as defined by a design matrix and the data; see further instructions in the code cell). Define then a function that performs gradient descent optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ad34a2590d84258ff7309bc1ac01d8f",
     "grade": false,
     "grade_id": "P3gradient",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gradient_linear_regression(X_d, y, theta):\n",
    "    \"\"\"\n",
    "    Compute the gradient for the linear regression cost function at a specific parameter position.\n",
    "    \n",
    "    Args:\n",
    "        X_d: Design matrix of shape (m,n) with 'm' independent data\n",
    "               and 'n' features (ndarray).\n",
    "        y: Dependent data of size m (ndarray).\n",
    "        theta: List-like set of parameters (size n)\n",
    "                  \n",
    "    Returns:\n",
    "        Gradient vector at position theta, array of shape (n,1).\n",
    "    \"\"\"\n",
    "    (m,n) = X_d.shape\n",
    "    assert len(y)==m, f'The size of y must be {m}. It is: {len(y)}.'\n",
    "    y = y.reshape(-1,1) # Turn into a (m,1) array.\n",
    "    assert len(theta)==n, f'The parameter vector must be of size {n}. It is: {len(theta)}.'\n",
    "    \n",
    "    # \n",
    "    # YOUR CODE HERE\n",
    "    # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTS TO CHECK YOUR CODE\n",
    "# ---\n",
    "assert (gradient_linear_regression(design_matrix(X), y, [0,0,0])).shape==(3,1),\\\n",
    "    'Return object has wrong shape.'\n",
    "# Solution to normal equation\n",
    "theta_star = np.array([0.20661169, 1.10887503, 0.69743377])\n",
    "# Check gradient\n",
    "gradient_optimum = gradient_linear_regression(design_matrix(X), y, theta_star)\n",
    "assert (abs(gradient_optimum)<1e-7).all(), 'Gradient at optimum is not zero (elements > 10**-7)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a692178b37bed33f69931aeee313cea",
     "grade": false,
     "grade_id": "gradient_descent_function",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gradient_descent_linear_regression(X_d, y, theta_start, eta=0.1, n_iterations=1000):\n",
    "    \"\"\"\n",
    "    Find optimized parameters in linear regression using (batch) gradient descent.\n",
    "    \n",
    "    Args:\n",
    "        X_d: Design matrix of shape (m,n) with 'm' independent data\n",
    "               and 'n' features (ndarray).\n",
    "        y: Dependent data of size m (ndarray).\n",
    "        theta_start: List-like initial guess for parameters (size n) \n",
    "        eta: learning rate (default 0.1) (float)\n",
    "        n_iterations: Number of iterations (epochs) (default 1000) (integer)\n",
    "                  \n",
    "    Returns:\n",
    "        theta_optimum: Optimized parameters, array of shape (n,).\n",
    "    \"\"\"\n",
    "    (m,n) = X_d.shape\n",
    "    assert len(y)==m, f'The size of y must be {m}. It is: {len(y)}.'\n",
    "    y = y.reshape(-1,1) # Turn into a (m,1) array.\n",
    "    assert len(theta_start)==n, f'The initial guess must be of size {n}. It is: {len(theta_start)}.'\n",
    "    \n",
    "    # \n",
    "    # YOUR CODE HERE\n",
    "    # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fdb9afd94d064e8c098a430e490abfcf",
     "grade": true,
     "grade_id": "correct_gradient_descent_function",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TESTS TO CHECK YOUR CODE\n",
    "# ---\n",
    "X_d = design_matrix(X)\n",
    "assert (gradient_descent_linear_regression(X_d, y, [0,0,0], n_iterations=1)).shape==(3,),\\\n",
    "    'Return object has wrong shape. Maybe the `flatten` method will be useful?'\n",
    "theta_star = np.array([0.20661169, 1.10887503, 0.69743377])\n",
    "# Check gradient\n",
    "gradient_optimum = theta_star - gradient_descent_linear_regression(X_d, y, theta_star,eta=1.0, n_iterations=1)\n",
    "assert (abs(gradient_optimum)<1e-7).all(), 'Gradient at optimum is not zero (elements > 10**-7)'\n",
    "# Check final optimum (tolerance 10**-2)\n",
    "# Note that you might need to increase the number of iterations.\n",
    "theta_residuals = gradient_descent_linear_regression(X_d, y, [0,0,0],n_iterations=2000) - theta_star\n",
    "assert (abs(theta_residuals)<1e-2).all(), 'Residuals of GD optimum are too large (elements > 10**-2)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Comparison of solvers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasks (see also Yata)** \n",
    "Apply both your solver of the normal equation and your gradient descent optimizer to the same data and quadratic model that was introduced at the beginning of this problem.\n",
    "- Print and compare the coefficients from (i) the true polynomial data generator to the linear regression fits to the (noisy) data from both (ii) the exact solution of the normal equation and (iii) the result of the gradient descent optimization. \n",
    "- Plot the data and the model predictions in the same figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "642a2f14e390bd0e2401bd8cf81d08ba",
     "grade": false,
     "grade_id": "cell-fbd1f3bdda876913",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# 1. Print and compare the coefficients from \n",
    "#   (i) the true data generator, \n",
    "#   (ii) the solution of the normal equation, \n",
    "#   (iii) the optimum from gradient descent.\n",
    "#\n",
    "# 2. Plot the data, the true model and the fit model predictions in the same figure.\n",
    "\n",
    "# \n",
    "# YOUR CODE HERE\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Applying Bayesian rules of probability to a standard medical example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "047732edfc9bef96df36ebc94305b8c7",
     "grade": false,
     "grade_id": "cell-a717eb4d32ba845e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Suppose there is an unknown disease (call it UD) that does not give any symptoms in its early phase, but that there is a test for it.\n",
    "\n",
    "a. The false positive rate is 2.3%. (\"False positive\" means the test says you have UD, but you don't.) <br>\n",
    "b. The false negative rate is 1.4%. (\"False negative\" means you have UD, but the test says you don't.)\n",
    "\n",
    "Assume that 1 in 10,000 people have the disease. You are given the test and get a positive result.  Your ultimate goal is to find the probability that you actually have the disease. \n",
    "$% Some LaTeX definitions we'll use.\n",
    "\\newcommand{\\pr}{\\textrm{p}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7e3d6d1a8635628beb75d133afccc515",
     "grade": false,
     "grade_id": "cell-51752b16483bb655",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We'll do it using the Bayesian rules.\n",
    "\n",
    "We'll use the notation:\n",
    "\n",
    "* $H$ = \"you have UD\"\n",
    "* $\\overline H$ = \"you do not have UD\"  \n",
    "* $D$ = \"you test positive for UD\"\n",
    "* $\\overline D$ = \"you test negative for UD\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5e62ca260750658aa3c7f5783c560dc8",
     "grade": false,
     "grade_id": "cell-61c95058fe103533",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Tasks (see also Yata)** \n",
    "\n",
    "Answer the following questions. Some of them are repeated on Yata.\n",
    "\n",
    "a. *Before doing a calculation (or thinking too hard :), does your intuition tell you the probability you have the disease is high or low?*\n",
    "<br>\n",
    "\n",
    "b. *In the $p(\\cdot | \\cdot)$ notation, what is your ultimate goal?*\n",
    "<br>\n",
    "\n",
    "c. *Express the false positive rate in $p(\\cdot | \\cdot)$ notation.* \\[Ask yourself first: what is to the left of the bar?\\]\n",
    "<br>\n",
    "\n",
    "d. *Express the false negative rate in $p(\\cdot | \\cdot)$ notation. By applying the sum rule, what do you also know? (If you get stuck answering the question, do the next part first.)* \n",
    "<br>\n",
    "\n",
    "e. *Should $p(D|H) + p(D|\\overline H) = 1$?\n",
    "    Should $p(D|H) + p(\\overline D |H) = 1$?\n",
    "    (Hint: does the sum rule apply on the left or right of the $|$?)*\n",
    "<br>\n",
    "\n",
    "f. *Apply Bayes' theorem to your result for your ultimate goal (don't put in numbers yet).\n",
    "   What other probabilities do we need?*\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eeccf4e51901f05414de6f2de3386574",
     "grade": false,
     "grade_id": "bayes_medical",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is used only in the solution notebook.\n",
    "# \n",
    "# Please ignore the comment in this cell that says \"YOUR CODE HERE\". It gets added automatically.\n",
    "# No solution code is needed here.\n",
    "# ---\n",
    "# \n",
    "# YOUR CODE HERE\n",
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Applying Bayesian rules of probability to a standard medical example (cont.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasks (see also Yata)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c26443747ad7abc8240520552e29550",
     "grade": false,
     "grade_id": "medical_example",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Please fill the probabilities as values for the \n",
    "# corresponding keys in the following dictionary.\n",
    "medical_example_probabilities = {}\n",
    "medical_example_probabilities['p(D|Hbar)'] = 0.0\n",
    "medical_example_probabilities['p(Dbar|H)'] = 0.0\n",
    "medical_example_probabilities['p(D|H)'] = 0.0\n",
    "medical_example_probabilities['p(H,Hbar|D)'] = 0.0\n",
    "medical_example_probabilities['p(Hbar)'] = 0.0\n",
    "medical_example_probabilities['p(D)'] = 0.0\n",
    "medical_example_probabilities['p(H|D)'] = 0.0\n",
    "\n",
    "# \n",
    "# YOUR CODE HERE\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ed248809a8371c7e567206cc9226d26",
     "grade": true,
     "grade_id": "correct_1_medical_example",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "for key in ['p(D|Hbar)', 'p(Dbar|H)', 'p(D|H)']:\n",
    "    assert medical_example_probabilities[key] > 0.\n",
    "    assert medical_example_probabilities[key] < 1.\n",
    "    \n",
    "assert medical_example_probabilities['p(H,Hbar|D)'] <= 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f767d6ab42f1573d59d64de9f207cec",
     "grade": true,
     "grade_id": "correct_2_medical_example",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "for key in ['p(Hbar)', 'p(D)', 'p(H|D)']:\n",
    "    assert medical_example_probabilities[key] > 0.\n",
    "    assert medical_example_probabilities[key] < 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
